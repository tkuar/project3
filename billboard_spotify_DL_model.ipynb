{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependecies\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>spotify_track_explicit</th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>spotify_track_popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>...</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>week_pos</th>\n",
       "      <th>instance</th>\n",
       "      <th>peak_pos</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdictoTainy, Anuel AA &amp; Ozuna</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270740.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.836</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01700</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.623</td>\n",
       "      <td>80.002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Ones That Didn't Make It Back HomeJustin M...</td>\n",
       "      <td>country</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ShallowLady Gaga &amp; Bradley Cooper</td>\n",
       "      <td>pop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215733.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.385</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.323</td>\n",
       "      <td>95.799</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EnemiesPost Malone Featuring DaBaby</td>\n",
       "      <td>rap</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196760.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.674</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-4.169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.667</td>\n",
       "      <td>76.388</td>\n",
       "      <td>4.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bacc At It AgainYella Beezy, Gucci Mane &amp; Quavo</td>\n",
       "      <td>rap</td>\n",
       "      <td>1.0</td>\n",
       "      <td>228185.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.623</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-5.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00124</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.856</td>\n",
       "      <td>135.979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            track_id    genre  \\\n",
       "0                      AdictoTainy, Anuel AA & Ozuna      pop   \n",
       "1  The Ones That Didn't Make It Back HomeJustin M...  country   \n",
       "2                  ShallowLady Gaga & Bradley Cooper      pop   \n",
       "3                EnemiesPost Malone Featuring DaBaby      rap   \n",
       "4    Bacc At It AgainYella Beezy, Gucci Mane & Quavo      rap   \n",
       "\n",
       "   spotify_track_explicit  spotify_track_duration_ms  \\\n",
       "0                     0.0                   270740.0   \n",
       "1                     0.0                        0.0   \n",
       "2                     0.0                   215733.0   \n",
       "3                     1.0                   196760.0   \n",
       "4                     1.0                   228185.0   \n",
       "\n",
       "   spotify_track_popularity  danceability  energy   key  loudness  mode  ...  \\\n",
       "0                      91.0         0.734   0.836  10.0    -4.803   0.0  ...   \n",
       "1                       0.0         0.000   0.000   0.0     0.000   0.0  ...   \n",
       "2                      89.0         0.572   0.385   7.0    -6.362   1.0  ...   \n",
       "3                      86.0         0.542   0.674   6.0    -4.169   1.0  ...   \n",
       "4                      61.0         0.948   0.623   8.0    -5.725   0.0  ...   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  time_signature  \\\n",
       "0       0.01700          0.000016    0.1790    0.623   80.002             4.0   \n",
       "1       0.00000          0.000000    0.0000    0.000    0.000             0.0   \n",
       "2       0.37100          0.000000    0.2310    0.323   95.799             4.0   \n",
       "3       0.05880          0.000000    0.0955    0.667   76.388             4.0   \n",
       "4       0.00124          0.000001    0.0716    0.856  135.979             4.0   \n",
       "\n",
       "   week_pos  instance  peak_pos  weeks_on_chart  \n",
       "0      98.0       1.0      86.0             2.0  \n",
       "1     100.0       1.0     100.0             1.0  \n",
       "2      28.0       1.0      28.0             1.0  \n",
       "3      98.0       1.0      16.0            15.0  \n",
       "4      94.0       1.0      94.0             3.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the billboard data into pandas\n",
    "df2 = pd.read_csv('data/grouped_audio_billboard_genre_data.csv')\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df2 = df2.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df2 = df2.dropna()\n",
    "df2.head()\n",
    "\n",
    "# Display dataframe \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning numbers to genre\n",
    "df2['genre'] = df2['genre'].replace('pop',float(0)).replace('country',float(1))\\\n",
    ".replace('hiphop',float(2)).replace('other',float(3)).replace('latin',float(3)).replace('latin',float(4))\\\n",
    ".replace('house',float(5)).replace('folk',float(6)).replace('r&b',float(7)).replace('adult standards',float(8))\\\n",
    ".replace('rock',float(9)).replace('metal',float(10)).replace('show tunes',float(11)).replace('soul',float(12))\\\n",
    ".replace('rap',float(13)).replace('jazz',float(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize variable into equal-sized buckets\n",
    "df2['target'] = pd.qcut(df2['peak_pos'],10, labels = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Train Test Split\n",
    "\n",
    "Use `target`for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = pd.Series(df2[\"target\"])\n",
    "X = df2.drop(columns=[\"track_id\", \"target\" ,'peak_pos'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28375.000000\n",
       "mean         4.339912\n",
       "std          2.802909\n",
       "min          0.000000\n",
       "25%          2.000000\n",
       "50%          4.000000\n",
       "75%          7.000000\n",
       "max          9.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>spotify_track_explicit</th>\n",
       "      <th>spotify_track_duration_ms</th>\n",
       "      <th>spotify_track_popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>week_pos</th>\n",
       "      <th>instance</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11734</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245640.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.548</td>\n",
       "      <td>108.873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28040</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258399.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.744</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-6.480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.655</td>\n",
       "      <td>96.596</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12045</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240866.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.677</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-7.278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.558</td>\n",
       "      <td>135.012</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14139</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.464</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-11.080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.921</td>\n",
       "      <td>124.553</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23223</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135506.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.259</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-14.393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.485</td>\n",
       "      <td>124.863</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189946.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.467</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.735</td>\n",
       "      <td>107.053</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17289</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151866.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.656</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-7.156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>0.2590</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.771</td>\n",
       "      <td>161.895</td>\n",
       "      <td>4.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162986.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.649</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-9.411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.831</td>\n",
       "      <td>96.111</td>\n",
       "      <td>4.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233506.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.565</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-10.027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.924</td>\n",
       "      <td>116.610</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229320.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.112</td>\n",
       "      <td>97.949</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21281 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       genre  spotify_track_explicit  spotify_track_duration_ms  \\\n",
       "11734    9.0                     0.0                   245640.0   \n",
       "28040    9.0                     0.0                   258399.0   \n",
       "12045    3.0                     0.0                   240866.0   \n",
       "14139    9.0                     0.0                   132280.0   \n",
       "23223    8.0                     0.0                   135506.0   \n",
       "...      ...                     ...                        ...   \n",
       "10955   14.0                     0.0                   189946.0   \n",
       "17289   14.0                     0.0                   151866.0   \n",
       "5192     9.0                     0.0                   162986.0   \n",
       "12172    9.0                     0.0                   233506.0   \n",
       "235      7.0                     0.0                   229320.0   \n",
       "\n",
       "       spotify_track_popularity  danceability  energy  key  loudness  mode  \\\n",
       "11734                      77.0         0.817   0.599  0.0    -9.249   0.0   \n",
       "28040                      63.0         0.569   0.744  8.0    -6.480   1.0   \n",
       "12045                      61.0         0.634   0.677  5.0    -7.278   0.0   \n",
       "14139                       0.0         0.714   0.464  8.0   -11.080   1.0   \n",
       "23223                      53.0         0.570   0.259  7.0   -14.393   1.0   \n",
       "...                         ...           ...     ...  ...       ...   ...   \n",
       "10955                      38.0         0.706   0.467  7.0    -9.523   1.0   \n",
       "17289                       7.0         0.652   0.656  7.0    -7.156   1.0   \n",
       "5192                       19.0         0.587   0.649  9.0    -9.411   1.0   \n",
       "12172                      63.0         0.626   0.565  9.0   -10.027   1.0   \n",
       "235                        82.0         0.596   0.552  0.0   -10.278   0.0   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "11734       0.0328        0.1320          0.000311    0.0873    0.548   \n",
       "28040       0.0298        0.0559          0.000003    0.0915    0.655   \n",
       "12045       0.0304        0.0117          0.001030    0.1260    0.558   \n",
       "14139       0.0514        0.9000          0.283000    0.1030    0.921   \n",
       "23223       0.0332        0.8050          0.000000    0.1120    0.485   \n",
       "...            ...           ...               ...       ...      ...   \n",
       "10955       0.0852        0.7130          0.000000    0.2530    0.735   \n",
       "17289       0.0967        0.2590          0.050900    0.1420    0.771   \n",
       "5192        0.0321        0.6050          0.000006    0.1390    0.831   \n",
       "12172       0.0271        0.1240          0.000000    0.0811    0.924   \n",
       "235         0.0970        0.0765          0.334000    0.1040    0.112   \n",
       "\n",
       "         tempo  time_signature  week_pos  instance  weeks_on_chart  \n",
       "11734  108.873             4.0      73.0       1.0             1.0  \n",
       "28040   96.596             4.0      34.0       1.0             1.0  \n",
       "12045  135.012             4.0      67.0       1.0             1.0  \n",
       "14139  124.553             4.0      80.0       1.0             2.0  \n",
       "23223  124.863             4.0     100.0       1.0             1.0  \n",
       "...        ...             ...       ...       ...             ...  \n",
       "10955  107.053             4.0      63.0       1.0             1.0  \n",
       "17289  161.895             4.0      92.0       1.0             1.0  \n",
       "5192    96.111             4.0      89.0       1.0             1.0  \n",
       "12172  116.610             4.0      65.0       1.0             1.0  \n",
       "235     97.949             4.0      45.0       1.0             1.0  \n",
       "\n",
       "[21281 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11734    2\n",
       "28040    0\n",
       "12045    1\n",
       "14139    2\n",
       "23223    9\n",
       "        ..\n",
       "10955    1\n",
       "17289    6\n",
       "5192     5\n",
       "12172    1\n",
       "235      0\n",
       "Name: target, Length: 21281, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "dump(X_scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21281, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='relu', input_dim=19))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                200       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 310\n",
      "Trainable params: 310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "666/666 - 2s - loss: 2.2735 - accuracy: 0.1443\n",
      "Epoch 2/400\n",
      "666/666 - 2s - loss: 2.1420 - accuracy: 0.2052\n",
      "Epoch 3/400\n",
      "666/666 - 2s - loss: 1.9902 - accuracy: 0.2570\n",
      "Epoch 4/400\n",
      "666/666 - 2s - loss: 1.8813 - accuracy: 0.3025\n",
      "Epoch 5/400\n",
      "666/666 - 1s - loss: 1.7980 - accuracy: 0.3293\n",
      "Epoch 6/400\n",
      "666/666 - 1s - loss: 1.7304 - accuracy: 0.3628\n",
      "Epoch 7/400\n",
      "666/666 - 1s - loss: 1.6731 - accuracy: 0.3929\n",
      "Epoch 8/400\n",
      "666/666 - 1s - loss: 1.6229 - accuracy: 0.4203\n",
      "Epoch 9/400\n",
      "666/666 - 1s - loss: 1.5797 - accuracy: 0.4488\n",
      "Epoch 10/400\n",
      "666/666 - 1s - loss: 1.5408 - accuracy: 0.4682\n",
      "Epoch 11/400\n",
      "666/666 - 1s - loss: 1.5060 - accuracy: 0.4882\n",
      "Epoch 12/400\n",
      "666/666 - 1s - loss: 1.4745 - accuracy: 0.4987\n",
      "Epoch 13/400\n",
      "666/666 - 1s - loss: 1.4461 - accuracy: 0.5168\n",
      "Epoch 14/400\n",
      "666/666 - 2s - loss: 1.4196 - accuracy: 0.5347\n",
      "Epoch 15/400\n",
      "666/666 - 2s - loss: 1.3958 - accuracy: 0.5514\n",
      "Epoch 16/400\n",
      "666/666 - 2s - loss: 1.3734 - accuracy: 0.5614\n",
      "Epoch 17/400\n",
      "666/666 - 1s - loss: 1.3522 - accuracy: 0.5721\n",
      "Epoch 18/400\n",
      "666/666 - 1s - loss: 1.3322 - accuracy: 0.5800\n",
      "Epoch 19/400\n",
      "666/666 - 2s - loss: 1.3132 - accuracy: 0.5904\n",
      "Epoch 20/400\n",
      "666/666 - 2s - loss: 1.2941 - accuracy: 0.5987\n",
      "Epoch 21/400\n",
      "666/666 - 2s - loss: 1.2750 - accuracy: 0.6111\n",
      "Epoch 22/400\n",
      "666/666 - 2s - loss: 1.2568 - accuracy: 0.6216\n",
      "Epoch 23/400\n",
      "666/666 - 2s - loss: 1.2398 - accuracy: 0.6319\n",
      "Epoch 24/400\n",
      "666/666 - 2s - loss: 1.2239 - accuracy: 0.6413\n",
      "Epoch 25/400\n",
      "666/666 - 2s - loss: 1.2080 - accuracy: 0.6503\n",
      "Epoch 26/400\n",
      "666/666 - 2s - loss: 1.1939 - accuracy: 0.6544\n",
      "Epoch 27/400\n",
      "666/666 - 2s - loss: 1.1795 - accuracy: 0.6603\n",
      "Epoch 28/400\n",
      "666/666 - 2s - loss: 1.1664 - accuracy: 0.6726\n",
      "Epoch 29/400\n",
      "666/666 - 2s - loss: 1.1536 - accuracy: 0.6727\n",
      "Epoch 30/400\n",
      "666/666 - 2s - loss: 1.1407 - accuracy: 0.6862\n",
      "Epoch 31/400\n",
      "666/666 - 2s - loss: 1.1292 - accuracy: 0.6853\n",
      "Epoch 32/400\n",
      "666/666 - 2s - loss: 1.1173 - accuracy: 0.6890\n",
      "Epoch 33/400\n",
      "666/666 - 1s - loss: 1.1063 - accuracy: 0.6916\n",
      "Epoch 34/400\n",
      "666/666 - 2s - loss: 1.0954 - accuracy: 0.6985\n",
      "Epoch 35/400\n",
      "666/666 - 2s - loss: 1.0849 - accuracy: 0.7085\n",
      "Epoch 36/400\n",
      "666/666 - 2s - loss: 1.0750 - accuracy: 0.7078\n",
      "Epoch 37/400\n",
      "666/666 - 2s - loss: 1.0657 - accuracy: 0.7174\n",
      "Epoch 38/400\n",
      "666/666 - 2s - loss: 1.0564 - accuracy: 0.7147\n",
      "Epoch 39/400\n",
      "666/666 - 2s - loss: 1.0466 - accuracy: 0.7222\n",
      "Epoch 40/400\n",
      "666/666 - 2s - loss: 1.0374 - accuracy: 0.7267\n",
      "Epoch 41/400\n",
      "666/666 - 2s - loss: 1.0293 - accuracy: 0.7324\n",
      "Epoch 42/400\n",
      "666/666 - 3s - loss: 1.0214 - accuracy: 0.7296\n",
      "Epoch 43/400\n",
      "666/666 - 2s - loss: 1.0130 - accuracy: 0.7372\n",
      "Epoch 44/400\n",
      "666/666 - 3s - loss: 1.0051 - accuracy: 0.7397\n",
      "Epoch 45/400\n",
      "666/666 - 5s - loss: 0.9979 - accuracy: 0.7443\n",
      "Epoch 46/400\n",
      "666/666 - 8s - loss: 0.9908 - accuracy: 0.7421\n",
      "Epoch 47/400\n",
      "666/666 - 2s - loss: 0.9827 - accuracy: 0.7491\n",
      "Epoch 48/400\n",
      "666/666 - 2s - loss: 0.9762 - accuracy: 0.7509\n",
      "Epoch 49/400\n",
      "666/666 - 3s - loss: 0.9708 - accuracy: 0.7502\n",
      "Epoch 50/400\n",
      "666/666 - 2s - loss: 0.9632 - accuracy: 0.7572\n",
      "Epoch 51/400\n",
      "666/666 - 2s - loss: 0.9569 - accuracy: 0.7607\n",
      "Epoch 52/400\n",
      "666/666 - 2s - loss: 0.9505 - accuracy: 0.7589\n",
      "Epoch 53/400\n",
      "666/666 - 2s - loss: 0.9446 - accuracy: 0.7663\n",
      "Epoch 54/400\n",
      "666/666 - 2s - loss: 0.9399 - accuracy: 0.7655\n",
      "Epoch 55/400\n",
      "666/666 - 2s - loss: 0.9323 - accuracy: 0.7695\n",
      "Epoch 56/400\n",
      "666/666 - 2s - loss: 0.9281 - accuracy: 0.7674\n",
      "Epoch 57/400\n",
      "666/666 - 2s - loss: 0.9216 - accuracy: 0.7742\n",
      "Epoch 58/400\n",
      "666/666 - 1s - loss: 0.9167 - accuracy: 0.7727\n",
      "Epoch 59/400\n",
      "666/666 - 2s - loss: 0.9109 - accuracy: 0.7747\n",
      "Epoch 60/400\n",
      "666/666 - 1s - loss: 0.9059 - accuracy: 0.7803\n",
      "Epoch 61/400\n",
      "666/666 - 2s - loss: 0.9007 - accuracy: 0.7822\n",
      "Epoch 62/400\n",
      "666/666 - 2s - loss: 0.8953 - accuracy: 0.7830\n",
      "Epoch 63/400\n",
      "666/666 - 1s - loss: 0.8912 - accuracy: 0.7901\n",
      "Epoch 64/400\n",
      "666/666 - 1s - loss: 0.8858 - accuracy: 0.7913\n",
      "Epoch 65/400\n",
      "666/666 - 1s - loss: 0.8812 - accuracy: 0.7903\n",
      "Epoch 66/400\n",
      "666/666 - 1s - loss: 0.8769 - accuracy: 0.7901\n",
      "Epoch 67/400\n",
      "666/666 - 1s - loss: 0.8728 - accuracy: 0.7954\n",
      "Epoch 68/400\n",
      "666/666 - 1s - loss: 0.8678 - accuracy: 0.7968\n",
      "Epoch 69/400\n",
      "666/666 - 1s - loss: 0.8639 - accuracy: 0.7973\n",
      "Epoch 70/400\n",
      "666/666 - 1s - loss: 0.8593 - accuracy: 0.8015\n",
      "Epoch 71/400\n",
      "666/666 - 1s - loss: 0.8556 - accuracy: 0.8009\n",
      "Epoch 72/400\n",
      "666/666 - 1s - loss: 0.8519 - accuracy: 0.8013\n",
      "Epoch 73/400\n",
      "666/666 - 1s - loss: 0.8476 - accuracy: 0.8038\n",
      "Epoch 74/400\n",
      "666/666 - 1s - loss: 0.8439 - accuracy: 0.8071\n",
      "Epoch 75/400\n",
      "666/666 - 1s - loss: 0.8416 - accuracy: 0.8080\n",
      "Epoch 76/400\n",
      "666/666 - 1s - loss: 0.8372 - accuracy: 0.8083\n",
      "Epoch 77/400\n",
      "666/666 - 1s - loss: 0.8340 - accuracy: 0.8090\n",
      "Epoch 78/400\n",
      "666/666 - 1s - loss: 0.8307 - accuracy: 0.8081\n",
      "Epoch 79/400\n",
      "666/666 - 1s - loss: 0.8265 - accuracy: 0.8104\n",
      "Epoch 80/400\n",
      "666/666 - 1s - loss: 0.8237 - accuracy: 0.8169\n",
      "Epoch 81/400\n",
      "666/666 - 1s - loss: 0.8209 - accuracy: 0.8150\n",
      "Epoch 82/400\n",
      "666/666 - 1s - loss: 0.8175 - accuracy: 0.8164\n",
      "Epoch 83/400\n",
      "666/666 - 1s - loss: 0.8152 - accuracy: 0.8194\n",
      "Epoch 84/400\n",
      "666/666 - 1s - loss: 0.8113 - accuracy: 0.8163\n",
      "Epoch 85/400\n",
      "666/666 - 1s - loss: 0.8093 - accuracy: 0.8210\n",
      "Epoch 86/400\n",
      "666/666 - 1s - loss: 0.8064 - accuracy: 0.8198\n",
      "Epoch 87/400\n",
      "666/666 - 1s - loss: 0.8038 - accuracy: 0.8249\n",
      "Epoch 88/400\n",
      "666/666 - 1s - loss: 0.7999 - accuracy: 0.8237\n",
      "Epoch 89/400\n",
      "666/666 - 1s - loss: 0.7984 - accuracy: 0.8245\n",
      "Epoch 90/400\n",
      "666/666 - 1s - loss: 0.7947 - accuracy: 0.8263\n",
      "Epoch 91/400\n",
      "666/666 - 1s - loss: 0.7927 - accuracy: 0.8310\n",
      "Epoch 92/400\n",
      "666/666 - 1s - loss: 0.7905 - accuracy: 0.8303\n",
      "Epoch 93/400\n",
      "666/666 - 1s - loss: 0.7877 - accuracy: 0.8305\n",
      "Epoch 94/400\n",
      "666/666 - 1s - loss: 0.7853 - accuracy: 0.8329\n",
      "Epoch 95/400\n",
      "666/666 - 1s - loss: 0.7833 - accuracy: 0.8322\n",
      "Epoch 96/400\n",
      "666/666 - 1s - loss: 0.7802 - accuracy: 0.8361\n",
      "Epoch 97/400\n",
      "666/666 - 1s - loss: 0.7785 - accuracy: 0.8324\n",
      "Epoch 98/400\n",
      "666/666 - 1s - loss: 0.7759 - accuracy: 0.8340\n",
      "Epoch 99/400\n",
      "666/666 - 1s - loss: 0.7744 - accuracy: 0.8367\n",
      "Epoch 100/400\n",
      "666/666 - 1s - loss: 0.7717 - accuracy: 0.8381\n",
      "Epoch 101/400\n",
      "666/666 - 1s - loss: 0.7691 - accuracy: 0.8367\n",
      "Epoch 102/400\n",
      "666/666 - 1s - loss: 0.7674 - accuracy: 0.8394\n",
      "Epoch 103/400\n",
      "666/666 - 1s - loss: 0.7655 - accuracy: 0.8407\n",
      "Epoch 104/400\n",
      "666/666 - 1s - loss: 0.7629 - accuracy: 0.8380\n",
      "Epoch 105/400\n",
      "666/666 - 1s - loss: 0.7607 - accuracy: 0.8403\n",
      "Epoch 106/400\n",
      "666/666 - 1s - loss: 0.7599 - accuracy: 0.8427\n",
      "Epoch 107/400\n",
      "666/666 - 1s - loss: 0.7576 - accuracy: 0.8403\n",
      "Epoch 108/400\n",
      "666/666 - 1s - loss: 0.7552 - accuracy: 0.8413\n",
      "Epoch 109/400\n",
      "666/666 - 1s - loss: 0.7541 - accuracy: 0.8420\n",
      "Epoch 110/400\n",
      "666/666 - 1s - loss: 0.7517 - accuracy: 0.8447\n",
      "Epoch 111/400\n",
      "666/666 - 1s - loss: 0.7496 - accuracy: 0.8496\n",
      "Epoch 112/400\n",
      "666/666 - 2s - loss: 0.7477 - accuracy: 0.8466\n",
      "Epoch 113/400\n",
      "666/666 - 2s - loss: 0.7465 - accuracy: 0.8465\n",
      "Epoch 114/400\n",
      "666/666 - 2s - loss: 0.7437 - accuracy: 0.8504\n",
      "Epoch 115/400\n",
      "666/666 - 2s - loss: 0.7422 - accuracy: 0.8482\n",
      "Epoch 116/400\n",
      "666/666 - 2s - loss: 0.7408 - accuracy: 0.8463\n",
      "Epoch 117/400\n",
      "666/666 - 2s - loss: 0.7422 - accuracy: 0.8471\n",
      "Epoch 118/400\n",
      "666/666 - 2s - loss: 0.7366 - accuracy: 0.8531\n",
      "Epoch 119/400\n",
      "666/666 - 2s - loss: 0.7357 - accuracy: 0.8487\n",
      "Epoch 120/400\n",
      "666/666 - 2s - loss: 0.7345 - accuracy: 0.8530\n",
      "Epoch 121/400\n",
      "666/666 - 1s - loss: 0.7325 - accuracy: 0.8534\n",
      "Epoch 122/400\n",
      "666/666 - 1s - loss: 0.7311 - accuracy: 0.8553\n",
      "Epoch 123/400\n",
      "666/666 - 1s - loss: 0.7290 - accuracy: 0.8549\n",
      "Epoch 124/400\n",
      "666/666 - 1s - loss: 0.7285 - accuracy: 0.8527\n",
      "Epoch 125/400\n",
      "666/666 - 1s - loss: 0.7262 - accuracy: 0.8531\n",
      "Epoch 126/400\n",
      "666/666 - 1s - loss: 0.7239 - accuracy: 0.8564\n",
      "Epoch 127/400\n",
      "666/666 - 2s - loss: 0.7233 - accuracy: 0.8562\n",
      "Epoch 128/400\n",
      "666/666 - 1s - loss: 0.7214 - accuracy: 0.8548\n",
      "Epoch 129/400\n",
      "666/666 - 1s - loss: 0.7199 - accuracy: 0.8592\n",
      "Epoch 130/400\n",
      "666/666 - 2s - loss: 0.7183 - accuracy: 0.8535\n",
      "Epoch 131/400\n",
      "666/666 - 2s - loss: 0.7166 - accuracy: 0.8594\n",
      "Epoch 132/400\n",
      "666/666 - 1s - loss: 0.7157 - accuracy: 0.8549\n",
      "Epoch 133/400\n",
      "666/666 - 1s - loss: 0.7141 - accuracy: 0.8601\n",
      "Epoch 134/400\n",
      "666/666 - 1s - loss: 0.7130 - accuracy: 0.8618\n",
      "Epoch 135/400\n",
      "666/666 - 1s - loss: 0.7113 - accuracy: 0.8604\n",
      "Epoch 136/400\n",
      "666/666 - 1s - loss: 0.7101 - accuracy: 0.8588\n",
      "Epoch 137/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 - 1s - loss: 0.7082 - accuracy: 0.8614\n",
      "Epoch 138/400\n",
      "666/666 - 1s - loss: 0.7075 - accuracy: 0.8609\n",
      "Epoch 139/400\n",
      "666/666 - 1s - loss: 0.7051 - accuracy: 0.8649\n",
      "Epoch 140/400\n",
      "666/666 - 1s - loss: 0.7040 - accuracy: 0.8619\n",
      "Epoch 141/400\n",
      "666/666 - 1s - loss: 0.7021 - accuracy: 0.8611\n",
      "Epoch 142/400\n",
      "666/666 - 1s - loss: 0.7016 - accuracy: 0.8638\n",
      "Epoch 143/400\n",
      "666/666 - 1s - loss: 0.6996 - accuracy: 0.8642\n",
      "Epoch 144/400\n",
      "666/666 - 1s - loss: 0.6987 - accuracy: 0.8630\n",
      "Epoch 145/400\n",
      "666/666 - 1s - loss: 0.6969 - accuracy: 0.8651\n",
      "Epoch 146/400\n",
      "666/666 - 1s - loss: 0.6966 - accuracy: 0.8666\n",
      "Epoch 147/400\n",
      "666/666 - 1s - loss: 0.6939 - accuracy: 0.8661\n",
      "Epoch 148/400\n",
      "666/666 - 1s - loss: 0.6934 - accuracy: 0.8673\n",
      "Epoch 149/400\n",
      "666/666 - 1s - loss: 0.6920 - accuracy: 0.8674\n",
      "Epoch 150/400\n",
      "666/666 - 1s - loss: 0.6912 - accuracy: 0.8664\n",
      "Epoch 151/400\n",
      "666/666 - 1s - loss: 0.6900 - accuracy: 0.8676\n",
      "Epoch 152/400\n",
      "666/666 - 1s - loss: 0.6883 - accuracy: 0.8664\n",
      "Epoch 153/400\n",
      "666/666 - 1s - loss: 0.6870 - accuracy: 0.8692\n",
      "Epoch 154/400\n",
      "666/666 - 1s - loss: 0.6855 - accuracy: 0.8687\n",
      "Epoch 155/400\n",
      "666/666 - 1s - loss: 0.6845 - accuracy: 0.8689\n",
      "Epoch 156/400\n",
      "666/666 - 1s - loss: 0.6845 - accuracy: 0.8694\n",
      "Epoch 157/400\n",
      "666/666 - 1s - loss: 0.6833 - accuracy: 0.8708\n",
      "Epoch 158/400\n",
      "666/666 - 1s - loss: 0.6808 - accuracy: 0.8709\n",
      "Epoch 159/400\n",
      "666/666 - 1s - loss: 0.6803 - accuracy: 0.8707\n",
      "Epoch 160/400\n",
      "666/666 - 1s - loss: 0.6789 - accuracy: 0.8697\n",
      "Epoch 161/400\n",
      "666/666 - 1s - loss: 0.6785 - accuracy: 0.8710\n",
      "Epoch 162/400\n",
      "666/666 - 1s - loss: 0.6773 - accuracy: 0.8727\n",
      "Epoch 163/400\n",
      "666/666 - 1s - loss: 0.6767 - accuracy: 0.8707\n",
      "Epoch 164/400\n",
      "666/666 - 1s - loss: 0.6754 - accuracy: 0.8743\n",
      "Epoch 165/400\n",
      "666/666 - 1s - loss: 0.6747 - accuracy: 0.8739\n",
      "Epoch 166/400\n",
      "666/666 - 1s - loss: 0.6745 - accuracy: 0.8721\n",
      "Epoch 167/400\n",
      "666/666 - 2s - loss: 0.6728 - accuracy: 0.8764\n",
      "Epoch 168/400\n",
      "666/666 - 2s - loss: 0.6710 - accuracy: 0.8747\n",
      "Epoch 169/400\n",
      "666/666 - 2s - loss: 0.6705 - accuracy: 0.8751\n",
      "Epoch 170/400\n",
      "666/666 - 1s - loss: 0.6698 - accuracy: 0.8722\n",
      "Epoch 171/400\n",
      "666/666 - 1s - loss: 0.6685 - accuracy: 0.8767\n",
      "Epoch 172/400\n",
      "666/666 - 1s - loss: 0.6681 - accuracy: 0.8743\n",
      "Epoch 173/400\n",
      "666/666 - 1s - loss: 0.6667 - accuracy: 0.8753\n",
      "Epoch 174/400\n",
      "666/666 - 1s - loss: 0.6663 - accuracy: 0.8763\n",
      "Epoch 175/400\n",
      "666/666 - 1s - loss: 0.6653 - accuracy: 0.8742\n",
      "Epoch 176/400\n",
      "666/666 - 1s - loss: 0.6648 - accuracy: 0.8747\n",
      "Epoch 177/400\n",
      "666/666 - 1s - loss: 0.6631 - accuracy: 0.8781\n",
      "Epoch 178/400\n",
      "666/666 - 1s - loss: 0.6610 - accuracy: 0.8750\n",
      "Epoch 179/400\n",
      "666/666 - 1s - loss: 0.6606 - accuracy: 0.8779\n",
      "Epoch 180/400\n",
      "666/666 - 1s - loss: 0.6585 - accuracy: 0.8756\n",
      "Epoch 181/400\n",
      "666/666 - 1s - loss: 0.6582 - accuracy: 0.8775\n",
      "Epoch 182/400\n",
      "666/666 - 1s - loss: 0.6569 - accuracy: 0.8785\n",
      "Epoch 183/400\n",
      "666/666 - 1s - loss: 0.6559 - accuracy: 0.8753\n",
      "Epoch 184/400\n",
      "666/666 - 1s - loss: 0.6551 - accuracy: 0.8789\n",
      "Epoch 185/400\n",
      "666/666 - 1s - loss: 0.6532 - accuracy: 0.8813\n",
      "Epoch 186/400\n",
      "666/666 - 1s - loss: 0.6535 - accuracy: 0.8807\n",
      "Epoch 187/400\n",
      "666/666 - 1s - loss: 0.6523 - accuracy: 0.8833\n",
      "Epoch 188/400\n",
      "666/666 - 1s - loss: 0.6510 - accuracy: 0.8839\n",
      "Epoch 189/400\n",
      "666/666 - 1s - loss: 0.6501 - accuracy: 0.8810\n",
      "Epoch 190/400\n",
      "666/666 - 2s - loss: 0.6491 - accuracy: 0.8830\n",
      "Epoch 191/400\n",
      "666/666 - 2s - loss: 0.6491 - accuracy: 0.8796\n",
      "Epoch 192/400\n",
      "666/666 - 2s - loss: 0.6489 - accuracy: 0.8808\n",
      "Epoch 193/400\n",
      "666/666 - 2s - loss: 0.6479 - accuracy: 0.8821\n",
      "Epoch 194/400\n",
      "666/666 - 2s - loss: 0.6451 - accuracy: 0.8855\n",
      "Epoch 195/400\n",
      "666/666 - 1s - loss: 0.6460 - accuracy: 0.8786\n",
      "Epoch 196/400\n",
      "666/666 - 1s - loss: 0.6447 - accuracy: 0.8825\n",
      "Epoch 197/400\n",
      "666/666 - 1s - loss: 0.6441 - accuracy: 0.8851\n",
      "Epoch 198/400\n",
      "666/666 - 2s - loss: 0.6431 - accuracy: 0.8820\n",
      "Epoch 199/400\n",
      "666/666 - 2s - loss: 0.6436 - accuracy: 0.8832\n",
      "Epoch 200/400\n",
      "666/666 - 1s - loss: 0.6439 - accuracy: 0.8819\n",
      "Epoch 201/400\n",
      "666/666 - 1s - loss: 0.6409 - accuracy: 0.8848\n",
      "Epoch 202/400\n",
      "666/666 - 1s - loss: 0.6411 - accuracy: 0.8821\n",
      "Epoch 203/400\n",
      "666/666 - 1s - loss: 0.6402 - accuracy: 0.8883\n",
      "Epoch 204/400\n",
      "666/666 - 1s - loss: 0.6397 - accuracy: 0.8847\n",
      "Epoch 205/400\n",
      "666/666 - 1s - loss: 0.6384 - accuracy: 0.8862\n",
      "Epoch 206/400\n",
      "666/666 - 1s - loss: 0.6391 - accuracy: 0.8873\n",
      "Epoch 207/400\n",
      "666/666 - 1s - loss: 0.6387 - accuracy: 0.8843\n",
      "Epoch 208/400\n",
      "666/666 - 1s - loss: 0.6369 - accuracy: 0.8868\n",
      "Epoch 209/400\n",
      "666/666 - 1s - loss: 0.6360 - accuracy: 0.8879\n",
      "Epoch 210/400\n",
      "666/666 - 1s - loss: 0.6368 - accuracy: 0.8867\n",
      "Epoch 211/400\n",
      "666/666 - 1s - loss: 0.6352 - accuracy: 0.8859\n",
      "Epoch 212/400\n",
      "666/666 - 1s - loss: 0.6351 - accuracy: 0.8885\n",
      "Epoch 213/400\n",
      "666/666 - 1s - loss: 0.6351 - accuracy: 0.8833\n",
      "Epoch 214/400\n",
      "666/666 - 1s - loss: 0.6329 - accuracy: 0.8897\n",
      "Epoch 215/400\n",
      "666/666 - 1s - loss: 0.6339 - accuracy: 0.8850\n",
      "Epoch 216/400\n",
      "666/666 - 1s - loss: 0.6311 - accuracy: 0.8861\n",
      "Epoch 217/400\n",
      "666/666 - 2s - loss: 0.6315 - accuracy: 0.8873\n",
      "Epoch 218/400\n",
      "666/666 - 2s - loss: 0.6308 - accuracy: 0.8874\n",
      "Epoch 219/400\n",
      "666/666 - 2s - loss: 0.6299 - accuracy: 0.8900\n",
      "Epoch 220/400\n",
      "666/666 - 2s - loss: 0.6293 - accuracy: 0.8882\n",
      "Epoch 221/400\n",
      "666/666 - 2s - loss: 0.6287 - accuracy: 0.8890\n",
      "Epoch 222/400\n",
      "666/666 - 1s - loss: 0.6304 - accuracy: 0.8899\n",
      "Epoch 223/400\n",
      "666/666 - 1s - loss: 0.6288 - accuracy: 0.8905\n",
      "Epoch 224/400\n",
      "666/666 - 2s - loss: 0.6276 - accuracy: 0.8884\n",
      "Epoch 225/400\n",
      "666/666 - 2s - loss: 0.6273 - accuracy: 0.8892\n",
      "Epoch 226/400\n",
      "666/666 - 2s - loss: 0.6280 - accuracy: 0.8879\n",
      "Epoch 227/400\n",
      "666/666 - 2s - loss: 0.6261 - accuracy: 0.8900\n",
      "Epoch 228/400\n",
      "666/666 - 2s - loss: 0.6263 - accuracy: 0.8900\n",
      "Epoch 229/400\n",
      "666/666 - 2s - loss: 0.6262 - accuracy: 0.8856\n",
      "Epoch 230/400\n",
      "666/666 - 2s - loss: 0.6246 - accuracy: 0.8884\n",
      "Epoch 231/400\n",
      "666/666 - 2s - loss: 0.6240 - accuracy: 0.8913\n",
      "Epoch 232/400\n",
      "666/666 - 2s - loss: 0.6234 - accuracy: 0.8896\n",
      "Epoch 233/400\n",
      "666/666 - 2s - loss: 0.6231 - accuracy: 0.8884\n",
      "Epoch 234/400\n",
      "666/666 - 1s - loss: 0.6238 - accuracy: 0.8837\n",
      "Epoch 235/400\n",
      "666/666 - 1s - loss: 0.6217 - accuracy: 0.8912\n",
      "Epoch 236/400\n",
      "666/666 - 1s - loss: 0.6214 - accuracy: 0.8911\n",
      "Epoch 237/400\n",
      "666/666 - 1s - loss: 0.6216 - accuracy: 0.8906\n",
      "Epoch 238/400\n",
      "666/666 - 1s - loss: 0.6210 - accuracy: 0.8905\n",
      "Epoch 239/400\n",
      "666/666 - 1s - loss: 0.6206 - accuracy: 0.8894\n",
      "Epoch 240/400\n",
      "666/666 - 1s - loss: 0.6205 - accuracy: 0.8907\n",
      "Epoch 241/400\n",
      "666/666 - 1s - loss: 0.6186 - accuracy: 0.8891\n",
      "Epoch 242/400\n",
      "666/666 - 1s - loss: 0.6188 - accuracy: 0.8902\n",
      "Epoch 243/400\n",
      "666/666 - 1s - loss: 0.6177 - accuracy: 0.8939\n",
      "Epoch 244/400\n",
      "666/666 - 1s - loss: 0.6192 - accuracy: 0.8914\n",
      "Epoch 245/400\n",
      "666/666 - 1s - loss: 0.6177 - accuracy: 0.8917\n",
      "Epoch 246/400\n",
      "666/666 - 1s - loss: 0.6162 - accuracy: 0.8931\n",
      "Epoch 247/400\n",
      "666/666 - 1s - loss: 0.6167 - accuracy: 0.8917\n",
      "Epoch 248/400\n",
      "666/666 - 1s - loss: 0.6157 - accuracy: 0.8907\n",
      "Epoch 249/400\n",
      "666/666 - 1s - loss: 0.6158 - accuracy: 0.8896\n",
      "Epoch 250/400\n",
      "666/666 - 1s - loss: 0.6139 - accuracy: 0.8920\n",
      "Epoch 251/400\n",
      "666/666 - 1s - loss: 0.6137 - accuracy: 0.8947\n",
      "Epoch 252/400\n",
      "666/666 - 1s - loss: 0.6135 - accuracy: 0.8947\n",
      "Epoch 253/400\n",
      "666/666 - 1s - loss: 0.6118 - accuracy: 0.8925\n",
      "Epoch 254/400\n",
      "666/666 - 1s - loss: 0.6130 - accuracy: 0.8922\n",
      "Epoch 255/400\n",
      "666/666 - 1s - loss: 0.6128 - accuracy: 0.8921\n",
      "Epoch 256/400\n",
      "666/666 - 1s - loss: 0.6111 - accuracy: 0.8935\n",
      "Epoch 257/400\n",
      "666/666 - 1s - loss: 0.6120 - accuracy: 0.8923\n",
      "Epoch 258/400\n",
      "666/666 - 1s - loss: 0.6114 - accuracy: 0.8911\n",
      "Epoch 259/400\n",
      "666/666 - 1s - loss: 0.6117 - accuracy: 0.8934\n",
      "Epoch 260/400\n",
      "666/666 - 1s - loss: 0.6110 - accuracy: 0.8915\n",
      "Epoch 261/400\n",
      "666/666 - 1s - loss: 0.6107 - accuracy: 0.8932\n",
      "Epoch 262/400\n",
      "666/666 - 1s - loss: 0.6098 - accuracy: 0.8932\n",
      "Epoch 263/400\n",
      "666/666 - 1s - loss: 0.6087 - accuracy: 0.8956\n",
      "Epoch 264/400\n",
      "666/666 - 1s - loss: 0.6087 - accuracy: 0.8921\n",
      "Epoch 265/400\n",
      "666/666 - 1s - loss: 0.6092 - accuracy: 0.8928\n",
      "Epoch 266/400\n",
      "666/666 - 1s - loss: 0.6086 - accuracy: 0.8925\n",
      "Epoch 267/400\n",
      "666/666 - 1s - loss: 0.6071 - accuracy: 0.8954\n",
      "Epoch 268/400\n",
      "666/666 - 1s - loss: 0.6072 - accuracy: 0.8926\n",
      "Epoch 269/400\n",
      "666/666 - 1s - loss: 0.6071 - accuracy: 0.8946\n",
      "Epoch 270/400\n",
      "666/666 - 1s - loss: 0.6065 - accuracy: 0.8944\n",
      "Epoch 271/400\n",
      "666/666 - 1s - loss: 0.6066 - accuracy: 0.8935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/400\n",
      "666/666 - 1s - loss: 0.6057 - accuracy: 0.8938\n",
      "Epoch 273/400\n",
      "666/666 - 1s - loss: 0.6051 - accuracy: 0.8943\n",
      "Epoch 274/400\n",
      "666/666 - 1s - loss: 0.6047 - accuracy: 0.8955\n",
      "Epoch 275/400\n",
      "666/666 - 1s - loss: 0.6048 - accuracy: 0.8927\n",
      "Epoch 276/400\n",
      "666/666 - 1s - loss: 0.6042 - accuracy: 0.8930\n",
      "Epoch 277/400\n",
      "666/666 - 1s - loss: 0.6038 - accuracy: 0.8946\n",
      "Epoch 278/400\n",
      "666/666 - 1s - loss: 0.6031 - accuracy: 0.8948\n",
      "Epoch 279/400\n",
      "666/666 - 1s - loss: 0.6024 - accuracy: 0.8922\n",
      "Epoch 280/400\n",
      "666/666 - 1s - loss: 0.6058 - accuracy: 0.8903\n",
      "Epoch 281/400\n",
      "666/666 - 1s - loss: 0.6010 - accuracy: 0.8941\n",
      "Epoch 282/400\n",
      "666/666 - 1s - loss: 0.6027 - accuracy: 0.8938\n",
      "Epoch 283/400\n",
      "666/666 - 1s - loss: 0.6012 - accuracy: 0.8977\n",
      "Epoch 284/400\n",
      "666/666 - 1s - loss: 0.6009 - accuracy: 0.8964\n",
      "Epoch 285/400\n",
      "666/666 - 1s - loss: 0.6012 - accuracy: 0.8953\n",
      "Epoch 286/400\n",
      "666/666 - 1s - loss: 0.6012 - accuracy: 0.8947\n",
      "Epoch 287/400\n",
      "666/666 - 1s - loss: 0.6014 - accuracy: 0.8937\n",
      "Epoch 288/400\n",
      "666/666 - 1s - loss: 0.5999 - accuracy: 0.8959\n",
      "Epoch 289/400\n",
      "666/666 - 1s - loss: 0.5998 - accuracy: 0.8952\n",
      "Epoch 290/400\n",
      "666/666 - 1s - loss: 0.5990 - accuracy: 0.8981\n",
      "Epoch 291/400\n",
      "666/666 - 1s - loss: 0.5989 - accuracy: 0.8962\n",
      "Epoch 292/400\n",
      "666/666 - 1s - loss: 0.5981 - accuracy: 0.8960\n",
      "Epoch 293/400\n",
      "666/666 - 1s - loss: 0.5973 - accuracy: 0.8947\n",
      "Epoch 294/400\n",
      "666/666 - 1s - loss: 0.5975 - accuracy: 0.8975\n",
      "Epoch 295/400\n",
      "666/666 - 1s - loss: 0.5976 - accuracy: 0.8974\n",
      "Epoch 296/400\n",
      "666/666 - 1s - loss: 0.5975 - accuracy: 0.8936\n",
      "Epoch 297/400\n",
      "666/666 - 1s - loss: 0.5970 - accuracy: 0.8976\n",
      "Epoch 298/400\n",
      "666/666 - 1s - loss: 0.5971 - accuracy: 0.8951\n",
      "Epoch 299/400\n",
      "666/666 - 1s - loss: 0.5951 - accuracy: 0.8972\n",
      "Epoch 300/400\n",
      "666/666 - 1s - loss: 0.5956 - accuracy: 0.8965\n",
      "Epoch 301/400\n",
      "666/666 - 1s - loss: 0.5956 - accuracy: 0.8967\n",
      "Epoch 302/400\n",
      "666/666 - 1s - loss: 0.5945 - accuracy: 0.8964\n",
      "Epoch 303/400\n",
      "666/666 - 1s - loss: 0.5940 - accuracy: 0.8968\n",
      "Epoch 304/400\n",
      "666/666 - 1s - loss: 0.5948 - accuracy: 0.8970\n",
      "Epoch 305/400\n",
      "666/666 - 1s - loss: 0.5929 - accuracy: 0.8975\n",
      "Epoch 306/400\n",
      "666/666 - 1s - loss: 0.5948 - accuracy: 0.8962\n",
      "Epoch 307/400\n",
      "666/666 - 1s - loss: 0.5939 - accuracy: 0.9000\n",
      "Epoch 308/400\n",
      "666/666 - 1s - loss: 0.5934 - accuracy: 0.8943\n",
      "Epoch 309/400\n",
      "666/666 - 1s - loss: 0.5932 - accuracy: 0.8981\n",
      "Epoch 310/400\n",
      "666/666 - 1s - loss: 0.5934 - accuracy: 0.8947\n",
      "Epoch 311/400\n",
      "666/666 - 1s - loss: 0.5924 - accuracy: 0.9005\n",
      "Epoch 312/400\n",
      "666/666 - 1s - loss: 0.5934 - accuracy: 0.8971\n",
      "Epoch 313/400\n",
      "666/666 - 1s - loss: 0.5925 - accuracy: 0.8950\n",
      "Epoch 314/400\n",
      "666/666 - 1s - loss: 0.5921 - accuracy: 0.8948\n",
      "Epoch 315/400\n",
      "666/666 - 1s - loss: 0.5911 - accuracy: 0.8990\n",
      "Epoch 316/400\n",
      "666/666 - 1s - loss: 0.5904 - accuracy: 0.8981\n",
      "Epoch 317/400\n",
      "666/666 - 1s - loss: 0.5896 - accuracy: 0.8985\n",
      "Epoch 318/400\n",
      "666/666 - 1s - loss: 0.5900 - accuracy: 0.8988\n",
      "Epoch 319/400\n",
      "666/666 - 1s - loss: 0.5897 - accuracy: 0.8998\n",
      "Epoch 320/400\n",
      "666/666 - 1s - loss: 0.5902 - accuracy: 0.8976\n",
      "Epoch 321/400\n",
      "666/666 - 1s - loss: 0.5889 - accuracy: 0.8957\n",
      "Epoch 322/400\n",
      "666/666 - 1s - loss: 0.5893 - accuracy: 0.8960\n",
      "Epoch 323/400\n",
      "666/666 - 1s - loss: 0.5894 - accuracy: 0.8972\n",
      "Epoch 324/400\n",
      "666/666 - 1s - loss: 0.5888 - accuracy: 0.8994\n",
      "Epoch 325/400\n",
      "666/666 - 1s - loss: 0.5881 - accuracy: 0.8999\n",
      "Epoch 326/400\n",
      "666/666 - 1s - loss: 0.5887 - accuracy: 0.8986\n",
      "Epoch 327/400\n",
      "666/666 - 1s - loss: 0.5866 - accuracy: 0.9002\n",
      "Epoch 328/400\n",
      "666/666 - 1s - loss: 0.5881 - accuracy: 0.8962\n",
      "Epoch 329/400\n",
      "666/666 - 1s - loss: 0.5861 - accuracy: 0.9000\n",
      "Epoch 330/400\n",
      "666/666 - 1s - loss: 0.5868 - accuracy: 0.8997\n",
      "Epoch 331/400\n",
      "666/666 - 1s - loss: 0.5864 - accuracy: 0.8997\n",
      "Epoch 332/400\n",
      "666/666 - 1s - loss: 0.5863 - accuracy: 0.8993\n",
      "Epoch 333/400\n",
      "666/666 - 1s - loss: 0.5856 - accuracy: 0.8983\n",
      "Epoch 334/400\n",
      "666/666 - 1s - loss: 0.5852 - accuracy: 0.8988\n",
      "Epoch 335/400\n",
      "666/666 - 1s - loss: 0.5867 - accuracy: 0.8950\n",
      "Epoch 336/400\n",
      "666/666 - 1s - loss: 0.5840 - accuracy: 0.9009\n",
      "Epoch 337/400\n",
      "666/666 - 1s - loss: 0.5849 - accuracy: 0.8997\n",
      "Epoch 338/400\n",
      "666/666 - 1s - loss: 0.5840 - accuracy: 0.9008\n",
      "Epoch 339/400\n",
      "666/666 - 1s - loss: 0.5842 - accuracy: 0.9010\n",
      "Epoch 340/400\n",
      "666/666 - 1s - loss: 0.5841 - accuracy: 0.8950\n",
      "Epoch 341/400\n",
      "666/666 - 1s - loss: 0.5832 - accuracy: 0.9009\n",
      "Epoch 342/400\n",
      "666/666 - 1s - loss: 0.5843 - accuracy: 0.8984\n",
      "Epoch 343/400\n",
      "666/666 - 1s - loss: 0.5821 - accuracy: 0.9027\n",
      "Epoch 344/400\n",
      "666/666 - 1s - loss: 0.5847 - accuracy: 0.9012\n",
      "Epoch 345/400\n",
      "666/666 - 1s - loss: 0.5816 - accuracy: 0.8995\n",
      "Epoch 346/400\n",
      "666/666 - 1s - loss: 0.5824 - accuracy: 0.8995\n",
      "Epoch 347/400\n",
      "666/666 - 1s - loss: 0.5811 - accuracy: 0.9001\n",
      "Epoch 348/400\n",
      "666/666 - 1s - loss: 0.5815 - accuracy: 0.9015\n",
      "Epoch 349/400\n",
      "666/666 - 1s - loss: 0.5802 - accuracy: 0.9013\n",
      "Epoch 350/400\n",
      "666/666 - 1s - loss: 0.5811 - accuracy: 0.9005\n",
      "Epoch 351/400\n",
      "666/666 - 1s - loss: 0.5805 - accuracy: 0.8988\n",
      "Epoch 352/400\n",
      "666/666 - 1s - loss: 0.5806 - accuracy: 0.8995\n",
      "Epoch 353/400\n",
      "666/666 - 1s - loss: 0.5798 - accuracy: 0.9001\n",
      "Epoch 354/400\n",
      "666/666 - 1s - loss: 0.5791 - accuracy: 0.8995\n",
      "Epoch 355/400\n",
      "666/666 - 1s - loss: 0.5786 - accuracy: 0.8996\n",
      "Epoch 356/400\n",
      "666/666 - 1s - loss: 0.5796 - accuracy: 0.9013\n",
      "Epoch 357/400\n",
      "666/666 - 1s - loss: 0.5783 - accuracy: 0.9027\n",
      "Epoch 358/400\n",
      "666/666 - 1s - loss: 0.5786 - accuracy: 0.9007\n",
      "Epoch 359/400\n",
      "666/666 - 1s - loss: 0.5789 - accuracy: 0.8986\n",
      "Epoch 360/400\n",
      "666/666 - 1s - loss: 0.5781 - accuracy: 0.9003\n",
      "Epoch 361/400\n",
      "666/666 - 1s - loss: 0.5784 - accuracy: 0.9025\n",
      "Epoch 362/400\n",
      "666/666 - 1s - loss: 0.5783 - accuracy: 0.9011\n",
      "Epoch 363/400\n",
      "666/666 - 1s - loss: 0.5770 - accuracy: 0.9002\n",
      "Epoch 364/400\n",
      "666/666 - 1s - loss: 0.5756 - accuracy: 0.9041\n",
      "Epoch 365/400\n",
      "666/666 - 1s - loss: 0.5776 - accuracy: 0.8998\n",
      "Epoch 366/400\n",
      "666/666 - 1s - loss: 0.5764 - accuracy: 0.9036\n",
      "Epoch 367/400\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=400,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('Models/billb_spot_DL.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "billboard_spotify_model = load_model('Models/billb_spot_DL.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluating the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = billboard_spotify_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
